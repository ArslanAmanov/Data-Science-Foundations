{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series data is an important form of structured data in many different fields, such as finance,economics,ecology, neuroscience, and physics. Anything that is observed or measured at many points in time forms a time series. Many time series are fixed frequency, which is to say that data points occur at regular intervals according to some rule, such as every 15 seconds, every 5 minutes, or once per month. Time series can also be irregular without a fixed unit of time or offset between units. How you mark and refer to time series data depends on the application, and you may have one of the following:\n",
    "# Timestamps, specific instants in time \n",
    "# Fixed periods, such as the month January 2007 or the full year 2010\n",
    "# Intervals of time, indicated by a start and end timestamp. Periods can be thought of as special cases of intervals\n",
    "# Experiment or elapsed time; each timestamp is a measure of time relative to a particular start time (e.g., the diameter of a cookie baking each second since being placed in the oven)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date and Time Data Types and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-30 16:36:36.265225\n"
     ]
    }
   ],
   "source": [
    "#  The python standard library includes data types for date and time data, as well as calendar-related functionality.\n",
    "# The datetime, time, and calendar modules are the main places to start. The datetime.datetime type or simply datetime is widely used:\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2024, 1, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now.year, now.month, now.day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime stores both the date and time down to the microsecond. datetime.timedelta represents the temporal difference between tow datetime objects\"ch6_data loading_storage and file formats.ipynb\n",
    "delta = datetime(2011,1,7) - datetime(2008,6,24,8,15) # 2011-01-07 00:00:00 - 2008-06-24 08:15:00 = 926 days, 15:45:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "926"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56700"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can add (or substract) a timedelta or multiple thereof to a datetime object to yield a new shifted object:\n",
    "from datetime import timedelta \n",
    "start = datetime(2011,1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 1, 19, 0, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "start + timedelta(12) # 2011-01-19 00:00:00 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types in datetime module \n",
    "# date stores the calendar date(year, month, day) using the Gregorian calendar \n",
    "# time stores the time as hours, minutes, seconds, and microseconds\n",
    "# datetime stores both date and time\n",
    "# timedelta represents the difference between two datetime values as days, seconds, and microseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting between string and datetime \n",
    "\n",
    "datetime objects and pandas Timestamp objects can be converted to one another very easily:\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-30 16:48:01.991575'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from turtle import stamp\n",
    "\n",
    "\n",
    "stamp = datetime.now() # 2019-11-05 15:54:00.000000\n",
    "str(stamp) # '2019-11-05 15:54:00.000000' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-30'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stamp.strftime('%Y-%m-%d') # '2019-11-05' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a complete list of the format codes. These same format codes can be used to convert strings to dates using datetime.strptime: \n",
    "value = '2011-01-03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 1, 3, 0, 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strptime(value, '%Y-%m-%d') # datetime.datetime(2011, 1, 3, 0, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestrs= ['7/6/2011', '8/6/2011']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7/6/2011', '8/6/2011']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datestrs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2011, 7, 6, 0, 0), datetime.datetime(2011, 8, 6, 0, 0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[datetime.strptime(x, '%m/%d/%Y') for x in datestrs] # [datetime.datetime(2011, 7, 6, 0, 0), datetime.datetime(2011, 8, 6, 0, 0)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 1, 3, 0, 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datetime.strptime is the best way to parse a date with a known format. However, it can be a bit annoying to have to \n",
    "# write a format spec each time, especially for common date formats. \n",
    "# In this case, you can use the parser.parse method in the third-party dateutil package (this is installed automatically when you install pandas): \n",
    "from dateutil.parser import parse \n",
    "parse('2011-01-03') # datetime.datetime(2011, 1, 3, 0, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1997, 1, 31, 22, 45)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dateutil is capable of parsing most human-intelligible date representations: \n",
    "parse('Jan 31, 1997 10:45 PM') # datetime.datetime(1997, 1, 31, 22, 45) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 12, 6, 0, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In internationally locales, day apprearing before month is very common, so you can pass dayfirst=True to indicate this:\n",
    "parse('6/12/2011', dayfirst=True) # datetime.datetime(2011, 12, 6, 0, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas is generally oriented toward working with arrays of dates, whether used as an axis index or a column in a DataFrame.\n",
    "# The to_datetime method parses many different kinds of date representations. Standard date formats like ISO 8601 can be parsed very quickly: \n",
    "import pandas as pd \n",
    "datestrs = ['2011-07-06 12:00:00', '2011-08-06 00:00:00'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2011-07-06 12:00:00', '2011-08-06 00:00:00'], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(datestrs) # DatetimeIndex(['2011-07-06 12:00:00', '2011-08-06'], dtype='datetime64[ns]', freq=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It also handles values that should be considered missing (None, empty string, etc.): \n",
    "idx = pd.to_datetime(datestrs + [None]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2011-07-06 12:00:00', '2011-08-06 00:00:00', 'NaT'], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime format specification (ISO C89 compatible) \n",
    "# %Y 4-digit year\n",
    "# %y 2-digit year\n",
    "# %m 2-digit month [01,12]\n",
    "# %d 2-digit day [01,31]\n",
    "# %H Hour (24-hour clock)[00,23]\n",
    "# %I Hour (12-hour clock)[01,12]\n",
    "# %M 2-digit minute [00,59]\n",
    "# %S Second [00,61] (seconds 60,61 account for leap seconds)\n",
    "# %w Weekday as integer [0(Sunday),6]\n",
    "# %U Week number of the year [00,53]; Sunday is considered the first day of the week, and days before the first Sunday of the year are “week 0”\n",
    "# %W Week number of the year [00,53]; Monday is considered the first day of the week, and days before the first Monday of the year are “week 0”\n",
    "# %z UTC time zone offset as +HHMM or -HHMM; empty if time zone naive\n",
    "# %F Shortcut for %Y-%m-%d (e.g., 2012-4-18)\n",
    "# %D Shortcut for %m/%d/%y (e.g., 04/18/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-07-06 12:00:00')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datetime objects also have a number of locale-specific formatting options for systems in other countries or languages. \n",
    "# For example, in German, the day appears before the month:\n",
    "# 2011-03-12 04:00:00 PM -> 12.03.2011 16:00:00\n",
    "# The German locale (and others) can be indicated in pandas like so:\n",
    "pd.to_datetime(datestrs[0], dayfirst=True) # Timestamp('2011-06-07 12:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locale - specific date formatting \n",
    "# %a Weekday as locale’s abbreviated name. Sun, Mon, ..., Sat (en_US); So, Mo, ..., Sa (de_DE)\n",
    "# %A Weekday as locale’s full name. Sunday, Monday, ..., Saturday (en_US); Sonntag, Montag, ..., Samstag (de_DE)\n",
    "# %b Month as locale’s abbreviated name. Jan, Feb, ..., Dec (en_US); Jan, Feb, ..., Dez (de_DE)\n",
    "# %B Month as locale’s full name. January, February, ..., December (en_US); Januar, Februar, ..., Dezember (de_DE)\n",
    "# %c Locale’s appropriate date and time representation. Tue Aug 16 21:30:00 1988 (en_US); Di 16 Aug 21:30:00 1988 (de_DE)\n",
    "# %p Locale’s equivalent of either AM or PM. AM, PM (en_US); am, pm (de_DE)\n",
    "# %x Locale’s appropriate date representation. 08/16/88 (None); 08/16/1988 (en_US); 16.08.1988 (de_DE)\n",
    "# %X Locale’s appropriate time representation. 21:30:00 (en_US); 21:30:00 (de_DE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Basics \n",
    "The most basic kind of time series object in pandas is a Series indexed by timestamps, which is often represented external to pandas as Python strings or datetime objects: \n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dates = [\n",
    "    datetime(2011,1,2), datetime(2011,1,5), datetime(2011,1,7), \n",
    "    datetime(2011,1,8), datetime(2011,1,10), datetime(2011,1,12)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame \n",
    "import numpy as np \n",
    "ts = Series (np.random.randn(6), index=dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02   -0.191806\n",
       "2011-01-05    1.348229\n",
       "2011-01-07    0.228457\n",
       "2011-01-08    0.941104\n",
       "2011-01-10    2.017281\n",
       "2011-01-12    0.614095\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Under the hood, these datetime objects have been put in a DatatimeIndex: \n",
    "# and the variable ts is now of type TimeSeries \n",
    "type(ts) # pandas.core.series.Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2011-01-02', '2011-01-05', '2011-01-07', '2011-01-08',\n",
       "               '2011-01-10', '2011-01-12'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02   -0.383613\n",
       "2011-01-05         NaN\n",
       "2011-01-07    0.456914\n",
       "2011-01-08         NaN\n",
       "2011-01-10    4.034562\n",
       "2011-01-12         NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Like other Series, arithmetic operations between \n",
    "# differently-indexed time series automatically align on the dates: \n",
    "ts + ts[::2] # 2011-01-02 00:00:00   -0.168180\n",
    "            # 2011-01-05 00:00:00         NaN\n",
    "            # 2011-01-07 00:00:00   -0.759805\n",
    "            # 2011-01-08 00:00:00         NaN\n",
    "            # 2011-01-10 00:00:00    0.669935\n",
    "            # 2011-01-12 00:00:00         NaN\n",
    "            # dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas stores timestamps using NumPy's datetime64 data type at the nanosecond resolution: \n",
    "ts.index.dtype # dtype('<M8[ns]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar values from a DatetimeIndex are pandas Timestamp objects: \n",
    "stamp = ts.index[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-01-02 00:00:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stamp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Timestamp can be substituted anywhere you would use a datetime object. Additionally, it can store frequency \n",
    "# information (if any) and understands how to do time zone conversions and other kinds of manipulations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing, Selection, Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries is a subclass of Series and thus behaves in the same way with regard to many arithmetic functions: \n",
    "stamp = ts.index[2] # 2011-01-07 00:00:00 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22845706703857016"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[stamp] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0172809964902885"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As a convenience, you can also pass a string that is interpretable as a date: \n",
    "ts['1/10/2011'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0172809964902885"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['20110110']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For longer time series, a year or only a year and month can be passed to easily select slices of data: \n",
    "import pandas as pd \n",
    "longer_ts = Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01   -0.594228\n",
       "2000-01-02    0.433961\n",
       "2000-01-03    1.041535\n",
       "2000-01-04   -0.699783\n",
       "2000-01-05    0.638649\n",
       "                ...   \n",
       "2002-09-22   -0.231598\n",
       "2002-09-23   -0.961379\n",
       "2002-09-24    1.503900\n",
       "2002-09-25    0.589409\n",
       "2002-09-26   -1.130632\n",
       "Freq: D, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer_ts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001-01-01    0.852516\n",
       "2001-01-02    1.398564\n",
       "2001-01-03   -1.095709\n",
       "2001-01-04   -0.902604\n",
       "2001-01-05    0.683059\n",
       "                ...   \n",
       "2001-12-27   -0.866160\n",
       "2001-12-28   -0.595024\n",
       "2001-12-29    0.237672\n",
       "2001-12-30    0.085976\n",
       "2001-12-31    0.750141\n",
       "Freq: D, Length: 365, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer_ts['2001'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001-05-01   -0.608742\n",
       "2001-05-02   -0.318897\n",
       "2001-05-03    0.097457\n",
       "2001-05-04    0.828169\n",
       "2001-05-05    0.680986\n",
       "2001-05-06    0.123383\n",
       "2001-05-07   -1.711345\n",
       "2001-05-08   -1.253020\n",
       "2001-05-09   -0.599664\n",
       "2001-05-10    0.698987\n",
       "2001-05-11   -0.163755\n",
       "2001-05-12    1.368672\n",
       "2001-05-13   -0.028034\n",
       "2001-05-14    0.243480\n",
       "2001-05-15   -0.376212\n",
       "2001-05-16    0.890416\n",
       "2001-05-17    0.293890\n",
       "2001-05-18    0.772936\n",
       "2001-05-19    0.135351\n",
       "2001-05-20   -0.528528\n",
       "2001-05-21   -0.283064\n",
       "2001-05-22   -0.702420\n",
       "2001-05-23   -0.188870\n",
       "2001-05-24   -1.020628\n",
       "2001-05-25   -0.870698\n",
       "2001-05-26   -1.342409\n",
       "2001-05-27    1.240621\n",
       "2001-05-28    0.052077\n",
       "2001-05-29    0.661220\n",
       "2001-05-30    0.984947\n",
       "2001-05-31    0.689535\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer_ts['2001-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-07    0.228457\n",
       "2011-01-08    0.941104\n",
       "2011-01-10    2.017281\n",
       "2011-01-12    0.614095\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing with dates works just like with a regular Series: \n",
    "ts[datetime(2011,1,7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02   -0.191806\n",
       "2011-01-05    1.348229\n",
       "2011-01-07    0.228457\n",
       "2011-01-08    0.941104\n",
       "2011-01-10    2.017281\n",
       "2011-01-12    0.614095\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because most time series data is ordered chronologically, you can slice with timestamps not contained in a time series to perform a range query: \n",
    "ts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-07    0.228457\n",
       "2011-01-08    0.941104\n",
       "2011-01-10    2.017281\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['1/6/2011':'1/11/2011']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02   -0.191806\n",
       "2011-01-05    1.348229\n",
       "2011-01-07    0.228457\n",
       "2011-01-08    0.941104\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As before you can pass either a string date, datetime, or timestamp. \n",
    "# Remember that slicing in this manner produces views on the source time series just like slicing NumPy arrays. \n",
    "# There is an equivalent instance method truncate which slices a Series between two dates: \n",
    "\n",
    "ts.truncate(after='1/9/2011') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the above holds true for DataFrame, too, indexing on its rows: \n",
    "dates = pd.date_range('1/1/2000', periods=100, freq='W-WED') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = DataFrame(np.random.randn(100,4), index=dates, columns=['Colorado', 'Texas', 'New York', 'Ohio'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Colorado</th>\n",
       "      <th>Texas</th>\n",
       "      <th>New York</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-05-02</th>\n",
       "      <td>-0.028066</td>\n",
       "      <td>-2.563557</td>\n",
       "      <td>-0.591534</td>\n",
       "      <td>0.273903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-09</th>\n",
       "      <td>-0.934964</td>\n",
       "      <td>-0.973781</td>\n",
       "      <td>-0.289601</td>\n",
       "      <td>1.061917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-16</th>\n",
       "      <td>-0.796096</td>\n",
       "      <td>1.027706</td>\n",
       "      <td>0.925750</td>\n",
       "      <td>-2.077534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-23</th>\n",
       "      <td>1.042699</td>\n",
       "      <td>-0.311563</td>\n",
       "      <td>0.592067</td>\n",
       "      <td>-1.467479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-30</th>\n",
       "      <td>-0.150522</td>\n",
       "      <td>0.754206</td>\n",
       "      <td>-1.315557</td>\n",
       "      <td>-0.144438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Colorado     Texas  New York      Ohio\n",
       "2001-05-02 -0.028066 -2.563557 -0.591534  0.273903\n",
       "2001-05-09 -0.934964 -0.973781 -0.289601  1.061917\n",
       "2001-05-16 -0.796096  1.027706  0.925750 -2.077534\n",
       "2001-05-23  1.042699 -0.311563  0.592067 -1.467479\n",
       "2001-05-30 -0.150522  0.754206 -1.315557 -0.144438"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df.loc['5-2001'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series with Duplicate Indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In some applications, you may wish to use time series data indexed by timestamps as \n",
    "# if it were a fixed frequency like daily or monthly, even if it is not.\n",
    "# The asfreq method enables this. We use the same long_ts time series from above:\n",
    "\n",
    "dates = pd.DatetimeIndex(['1/1/2000', '1/2/2000', '1/2/2000', '1/2/2000', '1/3/2000']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    0\n",
       "2000-01-02    1\n",
       "2000-01-02    2\n",
       "2000-01-02    3\n",
       "2000-01-03    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_ts = Series(np.arange(5), index=dates)  \n",
    "dup_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can tell that the index is not unique by checking its is_unique property: \n",
    "dup_ts.index.is_unique # False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing into this time series will either produce scalar values or slices depending on whether a timestamp is duplicated:\n",
    "dup_ts['1/3/2000'] # 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-02    1\n",
       "2000-01-02    2\n",
       "2000-01-02    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_ts['1/2/2000'] # 1/2/2000    1 1/2/2000    2 1/2/2000    3 dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose you wanted to group the data by timestamp and apply a group function like sum. \n",
    "# One way to do this is to use the groupby and pass level=0 (the only level of indexing): \n",
    "grouped = dup_ts.groupby(level=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    0.0\n",
       "2000-01-02    2.0\n",
       "2000-01-03    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    1\n",
       "2000-01-02    3\n",
       "2000-01-03    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.count() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Ranges, Frequencies, and Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02   -0.191806\n",
       "2011-01-05    1.348229\n",
       "2011-01-07    0.228457\n",
       "2011-01-08    0.941104\n",
       "2011-01-10    2.017281\n",
       "2011-01-12    0.614095\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generic time series in pandas are assumed to be irregular, that is, they have no fixed frequency.For many applications \n",
    "# this is sufficient.However, it's often desirable to work relative to a fixed frequency, such as daily, monthly, or every 15 mins. \n",
    "# even if that means introducing missing values into a time series.\n",
    "# Fortunately, pandas has a full suite of standard time series frequencies and tools for resampling, inferring frequencies,\n",
    "# and generating fixed frequency date ranges. \n",
    "# For example, in the example time series, converting it to be fixed daily frequency can be accomplished by calling resample: \n",
    "\n",
    "ts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.resample.DatetimeIndexResampler object at 0x12e80a590>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts. resample('D') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Date Ranges \n",
    "While I used it previously without explanation, you may have guessed that pandas.date_range is responsible for generating a DatetimeIndex with an indicated length according to a particular frequency: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range('4/1/2012', '6/1/2012') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-04-01', '2012-04-02', '2012-04-03', '2012-04-04',\n",
       "               '2012-04-05', '2012-04-06', '2012-04-07', '2012-04-08',\n",
       "               '2012-04-09', '2012-04-10', '2012-04-11', '2012-04-12',\n",
       "               '2012-04-13', '2012-04-14', '2012-04-15', '2012-04-16',\n",
       "               '2012-04-17', '2012-04-18', '2012-04-19', '2012-04-20',\n",
       "               '2012-04-21', '2012-04-22', '2012-04-23', '2012-04-24',\n",
       "               '2012-04-25', '2012-04-26', '2012-04-27', '2012-04-28',\n",
       "               '2012-04-29', '2012-04-30', '2012-05-01', '2012-05-02',\n",
       "               '2012-05-03', '2012-05-04', '2012-05-05', '2012-05-06',\n",
       "               '2012-05-07', '2012-05-08', '2012-05-09', '2012-05-10',\n",
       "               '2012-05-11', '2012-05-12', '2012-05-13', '2012-05-14',\n",
       "               '2012-05-15', '2012-05-16', '2012-05-17', '2012-05-18',\n",
       "               '2012-05-19', '2012-05-20', '2012-05-21', '2012-05-22',\n",
       "               '2012-05-23', '2012-05-24', '2012-05-25', '2012-05-26',\n",
       "               '2012-05-27', '2012-05-28', '2012-05-29', '2012-05-30',\n",
       "               '2012-05-31', '2012-06-01'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2021-04-01', '2021-04-02', '2021-04-03', '2021-04-04',\n",
       "               '2021-04-05', '2021-04-06', '2021-04-07', '2021-04-08',\n",
       "               '2021-04-09', '2021-04-10', '2021-04-11', '2021-04-12',\n",
       "               '2021-04-13', '2021-04-14', '2021-04-15', '2021-04-16',\n",
       "               '2021-04-17', '2021-04-18', '2021-04-19', '2021-04-20',\n",
       "               '2021-04-21', '2021-04-22', '2021-04-23', '2021-04-24',\n",
       "               '2021-04-25'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By default, date_range generates daily timestamps.If you  pass only a start or end date, you must pass a number of periods to generate. \n",
    "pd.date_range(start='4/1/2021', periods=25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-31', '2000-02-29', '2000-03-31', '2000-04-28',\n",
       "               '2000-05-31', '2000-06-30', '2000-07-31', '2000-08-31',\n",
       "               '2000-09-29', '2000-10-31', '2000-11-30'],\n",
       "              dtype='datetime64[ns]', freq='BM')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The start and end dates define strict boundries for the  generated date index. For example, \n",
    "# if you wanted a date index containing the last business day of each month, \n",
    "# you can would pass the \"BM\"  frequency(business end of month) and only dates falling on or inside the date interval will be included: \n",
    "pd.date_range('1/1/2000', '12/1/2000', freq='BM' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2021-05-01 12:56:31', '2021-05-02 12:56:31',\n",
       "               '2021-05-03 12:56:31', '2021-05-04 12:56:31',\n",
       "               '2021-05-05 12:56:31'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date_range by default preserves the time(if any) of the start or end timestamp: \n",
    "pd.date_range('5/1/2021  12:56:31',  periods=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-05-02', '2012-05-03', '2012-05-04', '2012-05-05',\n",
       "               '2012-05-06'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sometimes you will have start or end with time information but want to generate a set of timestamp normalized to midnight as a convention. \n",
    "# To do this, there is a normalize option: \n",
    "\n",
    "pd.date_range('5/2/2012  12:56:31', periods=5, normalize=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequencies and Date Offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequencies in pandas are composed of a base frequency and multiplier.\n",
    "# Base frequencies are typically referred to by a string alias, like 'M' for monthly or 'H' for hourly. \n",
    "# For each base frequency, there is an object defined generally referred to as a date offset. \n",
    "\n",
    "from pandas.tseries.offsets import Hour, Minute \n",
    "hour= Hour() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Hour>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can define a multiple of an offset by passing an integer: \n",
    "four_hours = Hour(4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4 * Hours>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_hours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 04:00:00',\n",
       "               '2000-01-01 08:00:00', '2000-01-01 12:00:00',\n",
       "               '2000-01-01 16:00:00', '2000-01-01 20:00:00',\n",
       "               '2000-01-02 00:00:00', '2000-01-02 04:00:00',\n",
       "               '2000-01-02 08:00:00', '2000-01-02 12:00:00',\n",
       "               '2000-01-02 16:00:00', '2000-01-02 20:00:00',\n",
       "               '2000-01-03 00:00:00', '2000-01-03 04:00:00',\n",
       "               '2000-01-03 08:00:00', '2000-01-03 12:00:00',\n",
       "               '2000-01-03 16:00:00', '2000-01-03 20:00:00'],\n",
       "              dtype='datetime64[ns]', freq='4H')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In most applications, you would never need to explicitly create one of these objects, \n",
    "# instead using a string alias like 'H' or '4H'. \n",
    "# Putting an integer before the base frequency creates a multiple: \n",
    "pd.date_range('1/1/2000', '1/3/2000 23:59', freq='4h') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<150 * Minutes>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Many offsets can be combined together by addition: \n",
    "Hour(2) + Minute(30)  # <150 * Minutes> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 02:30:00',\n",
       "               '2000-01-01 05:00:00', '2000-01-01 07:30:00',\n",
       "               '2000-01-01 10:00:00', '2000-01-01 12:30:00',\n",
       "               '2000-01-01 15:00:00', '2000-01-01 17:30:00',\n",
       "               '2000-01-01 20:00:00', '2000-01-01 22:30:00'],\n",
       "              dtype='datetime64[ns]', freq='150T')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly, you can pass frequency strings like '2h30min' which will effectively be parsed to the same expression: \n",
    "pd.date_range('1/1/2000', periods=10, freq='2h30min') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Time Series Frequencies \n",
    "# Alias       Offset type       Description \n",
    "# D           Day              Calendar day\n",
    "# B           BusinessDay      Business day\n",
    "# H           Hour             Hourly\n",
    "# T or min   Minute           Minutely\n",
    "# S           Second           Secondly\n",
    "# L or ms    Milli             Millisecond\n",
    "# U           Micro            Microsecond\n",
    "# M           MonthEnd         Last calendar day of month\n",
    "# BM          BusinessMonthEnd Last business day of month\n",
    "# MS          MonthBegin       First calendar day of month\n",
    "# BMS         BusinessMonthBegin First weekday of month\n",
    "# W-MON, W-TUE, ... Week           Weekly on given day of week\n",
    "# WOM-1MON, WOM-2MON, ... WeekOfMonth     Generate weekly dates in the first, second, third, or fourth week of the month\n",
    "# Q-JAN, Q-FEB, ... QuarterEnd      Quarter end, anchored on last calendar day of month\n",
    "# BQ-JAN, BQ-FEB, ... BusinessQuarterEnd Quarter end, anchored on last weekday day of month\n",
    "# QS-JAN, QS-FEB, ... QuarterBegin    Quarter begin, anchored on first calendar day of month\n",
    "# BQS-JAN, BQS-FEB, ... BusinessQuarterBegin Quarter begin, anchored on first weekday day of month\n",
    "# A-JAN, A-FEB, ... YearEnd         Annual (year) end, anchored on last calendar day of given month\n",
    "# BA-JAN, BA-FEB, ... BusinessYearEnd Annual (year) end, anchored on last weekday day of given month\n",
    "# AS-JAN, AS-FEB, ... YearBegin       Annual (year) begin, anchored on first calendar day of given month\n",
    "# BAS-JAN, BAS-FEB, ... BusinessYearBegin Annual (year) begin, anchored on first weekday day of given month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week of month dates  \n",
    "One useful frequency class is “week of month,” starting with WOM. This enables you to get dates like the third Friday of each month: \n",
    "\n",
    "```python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range('1/1/2000', periods=100, freq='D') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2000-01-01 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-02 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-03 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-04 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-05 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-06 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-07 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-08 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-09 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-10 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-11 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-12 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-13 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-14 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-15 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-16 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-17 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-18 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-19 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-20 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-21 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-22 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-23 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-24 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-25 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-26 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-27 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-28 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-29 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-30 00:00:00', freq='D'),\n",
       " Timestamp('2000-01-31 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-01 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-02 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-03 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-04 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-05 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-06 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-07 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-08 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-09 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-10 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-11 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-12 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-13 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-14 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-15 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-16 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-17 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-18 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-19 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-20 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-21 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-22 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-23 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-24 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-25 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-26 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-27 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-28 00:00:00', freq='D'),\n",
       " Timestamp('2000-02-29 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-01 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-02 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-03 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-04 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-05 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-06 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-07 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-08 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-09 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-10 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-11 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-12 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-13 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-14 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-15 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-16 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-17 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-18 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-19 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-20 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-21 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-22 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-23 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-24 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-25 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-26 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-27 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-28 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-29 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-30 00:00:00', freq='D'),\n",
       " Timestamp('2000-03-31 00:00:00', freq='D'),\n",
       " Timestamp('2000-04-01 00:00:00', freq='D'),\n",
       " Timestamp('2000-04-02 00:00:00', freq='D'),\n",
       " Timestamp('2000-04-03 00:00:00', freq='D'),\n",
       " Timestamp('2000-04-04 00:00:00', freq='D'),\n",
       " Timestamp('2000-04-05 00:00:00', freq='D'),\n",
       " Timestamp('2000-04-06 00:00:00', freq='D'),\n",
       " Timestamp('2000-04-07 00:00:00', freq='D'),\n",
       " Timestamp('2000-04-08 00:00:00', freq='D'),\n",
       " Timestamp('2000-04-09 00:00:00', freq='D')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traders of US equity options will be familiar with the standard 3rd Friday of the month contracts. \n",
    "# You can define this with the 'WOM-3FRI' frequency: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shifting(Leading and Lagging) Data \n",
    "\"Shifting\" refers to moving data backward and forward through time. Both Series and DataFrame have a shift method for doing naive shifts forward or backward, leaving the index unmodified: \n",
    "\n",
    "```python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Series(np.random.randn(4), index=pd.date_range('1/1/2000', periods=4, freq='M')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31    1.125940\n",
       "2000-02-29    0.212157\n",
       "2000-03-31    0.877651\n",
       "2000-04-30   -0.917144\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31         NaN\n",
       "2000-02-29         NaN\n",
       "2000-03-31    1.125940\n",
       "2000-04-30    0.212157\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31    0.877651\n",
       "2000-02-29   -0.917144\n",
       "2000-03-31         NaN\n",
       "2000-04-30         NaN\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(-2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A common use of shift is computing percent changes in a time series or multiple time series as DataFrame columns.\n",
    "# This is expressed as: \n",
    "# (ts / ts.shift(1)) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-03-31    1.125940\n",
       "2000-04-30    0.212157\n",
       "2000-05-31    0.877651\n",
       "2000-06-30   -0.917144\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because naive shifts leave the index unmodified, some data is discarded. \n",
    "# Thus if the frequency is known, it can be passed to shift to advance the timestamp instead of simply the data: \n",
    "ts.shift(2, freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-02-03    1.125940\n",
       "2000-03-03    0.212157\n",
       "2000-04-03    0.877651\n",
       "2000-05-03   -0.917144\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(3, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-02-03    1.125940\n",
       "2000-03-03    0.212157\n",
       "2000-04-03    0.877651\n",
       "2000-05-03   -0.917144\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(1, freq='3D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shifting dates with offsets \n",
    "pandas has a number of custom offsets that can be used with the shift method. These are especially useful for time series with business day frequencies. \n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import Day, MonthEnd \n",
    "now = datetime(2011,11,17) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-11-20 00:00:00')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now + 3 * Day() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-11-30 00:00:00')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you add an anchored offset like MonthEnd, the first increment will roll forward a date to the next date according to the frequency rule: \n",
    "now + MonthEnd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-12-31 00:00:00')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now + MonthEnd(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anchored offsets can explicitly \"roll\" dates forward or backward using their rollforward and rollback methods,\n",
    "# respectively:\n",
    "offset = MonthEnd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-11-30 00:00:00')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset.rollforward(now) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-10-31 00:00:00')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset.rollback(now) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A clever use of date offsets is to use these methods with groupby:\n",
    "ts = Series(np.random.randn(20), index=pd.date_range('1/15/2000', periods=20, freq='4d')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31    0.097029\n",
       "2000-02-29    0.227088\n",
       "2000-03-31    0.191492\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.groupby(offset.rollforward).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31    0.097029\n",
       "2000-02-29    0.227088\n",
       "2000-03-31    0.191492\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Of course, an easier and faster way to do this is using resample:\n",
    "ts.resample('M').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Zone Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with time zones is generally considered one o f the most unpleasant parts of time series manipulation. \n",
    "# In particular, daylight savings time transitions are a common source of complication. \n",
    "# As such, many time series users choose to work with time seires in Coordinated universal Time or UTC, which is the successor to \n",
    "# Greenwich Mean Time and is the current international standard. \n",
    "\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytz.common_timezones[-5:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get a time zone object from pytz, use pytz.timezone: \n",
    "tz = pytz.timezone('America/New_York') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DstTzInfo 'America/New_York' LMT-1 day, 19:04:00 STD>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localization and Conversion \n",
    "By default, time series in pandas are time zone naive. For example, consider the following time series: \n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas import Series, DataFrame\n",
    "rng = pd.date_range('3/9/2012 9:30', periods=6, freq='D') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "ts = Series(np.random.randn(len(rng)), index=rng) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-09 09:30:00    0.353855\n",
       "2012-03-10 09:30:00    0.394750\n",
       "2012-03-11 09:30:00    1.686663\n",
       "2012-03-12 09:30:00    0.834828\n",
       "2012-03-13 09:30:00    0.315383\n",
       "2012-03-14 09:30:00   -0.198523\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion from naive to localized is handled by the tz_localize method: \n",
    "ts_utc = ts.tz_localize('UTC') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-09 09:30:00+00:00    0.353855\n",
       "2012-03-10 09:30:00+00:00    0.394750\n",
       "2012-03-11 09:30:00+00:00    1.686663\n",
       "2012-03-12 09:30:00+00:00    0.834828\n",
       "2012-03-13 09:30:00+00:00    0.315383\n",
       "2012-03-14 09:30:00+00:00   -0.198523\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-09 01:30:00-08:00    0.353855\n",
       "2012-03-10 01:30:00-08:00    0.394750\n",
       "2012-03-11 01:30:00-08:00    1.686663\n",
       "2012-03-12 02:30:00-07:00    0.834828\n",
       "2012-03-13 02:30:00-07:00    0.315383\n",
       "2012-03-14 02:30:00-07:00   -0.198523\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once a time series has been localized to a particular time zone, \n",
    "# it can be converted to another time zone with tz_convert: \n",
    "ts_utc.tz_convert('America/Los_Angeles') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
